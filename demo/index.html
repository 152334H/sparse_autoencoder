
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Sparse Autoencoder for Mechanistic Interpretability">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../contributing/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.10">
    
    
      
        <title>Demo - Sparse Autoencoder</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../css/material_extra.css">
    
      <link rel="stylesheet" href="../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="amber">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#sparse-autoencoder-training-demo" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Sparse Autoencoder" class="md-header__button md-logo" aria-label="Sparse Autoencoder" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sparse Autoencoder
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Demo
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="amber"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ai-safety-foundation/sparse_autoencoder" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-safety-foundation/sparse_autoencoder
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Sparse Autoencoder" class="md-nav__button md-logo" aria-label="Sparse Autoencoder" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sparse Autoencoder
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ai-safety-foundation/sparse_autoencoder" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-safety-foundation/sparse_autoencoder
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Demo
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Demo
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imports" class="md-nav__link">
    <span class="md-ellipsis">
      Imports
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-model" class="md-nav__link">
    <span class="md-ellipsis">
      Source Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Autoencoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Source dataset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-advice" class="md-nav__link">
    <span class="md-ellipsis">
      Training Advice
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../reference" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reference
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../citation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Citation
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imports" class="md-nav__link">
    <span class="md-ellipsis">
      Imports
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-model" class="md-nav__link">
    <span class="md-ellipsis">
      Source Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Autoencoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Source dataset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-advice" class="md-nav__link">
    <span class="md-ellipsis">
      Training Advice
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script>
(function() {
  function addWidgetsRenderer() {
    var requireJsScript = document.createElement('script');
    requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';

    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var jupyterWidgetsScript = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    jupyterWidgetsScript.src = widgetRendererSrc;

    document.body.appendChild(requireJsScript);
    document.body.appendChild(jupyterWidgetsScript);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="sparse-autoencoder-training-demo">Sparse Autoencoder Training Demo<a class="headerlink" href="#sparse-autoencoder-training-demo" title="Permanent link">¤</a></h1>
<p>This demo trains a sparse autoencoder on activations from a Tiny Stories 1M model.</p>
<p>To do this we setup a <em>source model</em> (the TinyStories model) that we want to generate activations
from, along with a <em>source dataset</em> of prompts to help generate these activations.</p>
<p>We also setup a <em>sparse autoencoder model</em> which we'll train on these generated activations, to
learn a sparse representation of them in higher dimensional space.</p>
<p>Finally we'll wrap this all together in a <em>pipeline</em>, which alternates between generating
activations (storing them in ram), and training the SAE on said activations.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">¤</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="imports">Imports<a class="headerlink" href="#imports" title="Permanent link">¤</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformer_lens</span> <span class="kn">import</span> <span class="n">HookedTransformer</span>
<span class="kn">from</span> <span class="nn">transformer_lens.utils</span> <span class="kn">import</span> <span class="n">get_device</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">PreTrainedTokenizerBase</span>
<span class="kn">import</span> <span class="nn">wandb</span>

<span class="kn">from</span> <span class="nn">sparse_autoencoder</span> <span class="kn">import</span> <span class="n">SparseAutoencoder</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.activation_resampler</span> <span class="kn">import</span> <span class="n">ActivationResampler</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.loss.learned_activations_l1</span> <span class="kn">import</span> <span class="n">LearnedActivationsL1Loss</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.loss.mse_reconstruction_loss</span> <span class="kn">import</span> <span class="n">MSEReconstructionLoss</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.loss.reducer</span> <span class="kn">import</span> <span class="n">LossReducer</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.optimizer.adam_with_reset</span> <span class="kn">import</span> <span class="n">AdamWithReset</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.source_data.text_dataset</span> <span class="kn">import</span> <span class="n">GenericTextDataset</span>
<span class="kn">from</span> <span class="nn">sparse_autoencoder.train.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>


<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># You will need a GPU</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
Using device: mps
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="hyperparameters">Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permanent link">¤</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The way this library works is that you can define your own hyper-parameters and then setup the
underlying components with them. This is extremely flexible, but to help you get started we've
included some common ones below along with some sensible defaults. You can also easily sweep through
multiple hyperparameters with <code>wandb.sweep</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">hyperparameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Expansion factor is the number of features in the sparse representation, relative to the</span>
    <span class="c1"># number of features in the original MLP layer. The original paper experimented with 1x to 256x,</span>
    <span class="c1"># and we have found that 4x is a good starting point.</span>
    <span class="s2">&quot;expansion_factor&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="c1"># L1 coefficient is the coefficient of the L1 regularization term (used to encourage sparsity).</span>
    <span class="s2">&quot;l1_coefficient&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="c1"># Adam parameters (set to the default ones here)</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s2">&quot;adam_beta_1&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="s2">&quot;adam_beta_2&quot;</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">,</span>
    <span class="s2">&quot;adam_epsilon&quot;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="s2">&quot;adam_weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="c1"># Batch sizes</span>
    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="mi">8192</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="source-model">Source Model<a class="headerlink" href="#source-model" title="Permanent link">¤</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The source model is just a <a href="https://github.com/neelnanda-io/TransformerLens">TransformerLens</a> model
(see <a href="https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html">here</a>
for a full list of supported models).</p>
<p>In this example we're training a sparse autoencoder on the activations from the first MLP layer, so
we'll also get some details about that hook point.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Source model setup with TransformerLens</span>
<span class="n">src_model_name</span> <span class="o">=</span> <span class="s2">&quot;tiny-stories-1M&quot;</span>
<span class="n">src_model</span> <span class="o">=</span> <span class="n">HookedTransformer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">src_model_name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="c1"># Details about the activations we&#39;ll train the sparse autoencoder on</span>
<span class="n">src_model_activation_hook_point</span> <span class="o">=</span> <span class="s2">&quot;blocks.0.mlp.hook_post&quot;</span>
<span class="n">src_model_activation_layer</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">src_d_mlp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">src_model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_mlp</span>  <span class="c1"># type: ignore (TransformerLens typing is currently broken)</span>

<span class="sa">f</span><span class="s2">&quot;Source: </span><span class="si">{</span><span class="n">src_model_name</span><span class="si">}</span><span class="s2">, Hook: </span><span class="si">{</span><span class="n">src_model_activation_hook_point</span><span class="si">}</span><span class="s2">, Features: </span><span class="si">{</span><span class="n">src_d_mlp</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>Using pad_token, but it is not set yet.
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Loaded pretrained model tiny-stories-1M into HookedTransformer
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>'Source: tiny-stories-1M, Hook: blocks.0.mlp.hook_post, Features: 256'</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="sparse-autoencoder">Sparse Autoencoder<a class="headerlink" href="#sparse-autoencoder" title="Permanent link">¤</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can then setup the sparse autoencoder. The default model (<code>SparseAutoencoder</code>) is setup as per
the original Anthropic paper <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">Towards Monosemanticity: Decomposing Language Models With Dictionary
Learning </a>.</p>
<p>However it's just a standard PyTorch model, so you can create your own model instead if you want to
use a different architecture. To do this you just need to extend the <code>AbstractAutoencoder</code>, and
optionally the underlying <code>AbstractEncoder</code>, <code>AbstractDecoder</code> and <code>AbstractOuterBias</code>. See these
classes (which are fully documented) for more details.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">expansion_factor</span> <span class="o">=</span> <span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;expansion_factor&quot;</span><span class="p">]</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">SparseAutoencoder</span><span class="p">(</span>
    <span class="n">n_input_features</span><span class="o">=</span><span class="n">src_d_mlp</span><span class="p">,</span>  <span class="c1"># size of the activations we are autoencoding</span>
    <span class="n">n_learned_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">src_d_mlp</span> <span class="o">*</span> <span class="n">expansion_factor</span><span class="p">),</span>  <span class="c1"># size of SAE</span>
    <span class="n">geometric_median_dataset</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">src_d_mlp</span><span class="p">),</span>  <span class="c1"># this is used to initialize the tied bias</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">autoencoder</span>  <span class="c1"># Print the model (it&#39;s pretty straightforward)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>SparseAutoencoder(
  (_pre_encoder_bias): TiedBias(position=pre_encoder)
  (_encoder): LinearEncoder(
    in_features=256, out_features=1024
    (activation_function): ReLU()
  )
  (_decoder): UnitNormDecoder(in_features=1024, out_features=256)
  (_post_decoder_bias): TiedBias(position=post_decoder)
)</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also want to setup an Optimizer and Loss function. In this case we'll also use the standard
approach from the original Anthropic paper. However you can create your own loss functions and
optimizers by extending <code>AbstractLoss</code> and <code>AbstractOptimizerWithReset</code> respectively.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># We use a loss reducer, which simply adds up the losses from the underlying loss functions.</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">LossReducer</span><span class="p">(</span>
    <span class="n">LearnedActivationsL1Loss</span><span class="p">(</span>
        <span class="n">l1_coefficient</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;l1_coefficient&quot;</span><span class="p">],</span>
    <span class="p">),</span>
    <span class="n">MSEReconstructionLoss</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">loss</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>LossReducer(
  (0): LearnedActivationsL1Loss(l1_coefficient=0.001)
  (1): MSEReconstructionLoss()
)</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamWithReset</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
    <span class="n">named_parameters</span><span class="o">=</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;adam_beta_1&quot;</span><span class="p">],</span> <span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;adam_beta_2&quot;</span><span class="p">]),</span>
    <span class="n">eps</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;adam_epsilon&quot;</span><span class="p">],</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;adam_weight_decay&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">optimizer</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>AdamWithReset (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we'll initialise an activation resampler.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">activation_resampler</span> <span class="o">=</span> <span class="n">ActivationResampler</span><span class="p">()</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="source-dataset">Source dataset<a class="headerlink" href="#source-dataset" title="Permanent link">¤</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is just a dataset of tokenized prompts, to be used in generating activations (which are in turn
used to train the SAE).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizerBase</span> <span class="o">=</span> <span class="n">src_model</span><span class="o">.</span><span class="n">tokenizer</span>  <span class="c1"># type: ignore</span>
<span class="n">source_data</span> <span class="o">=</span> <span class="n">GenericTextDataset</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">dataset_path</span><span class="o">=</span><span class="s2">&quot;roneneldan/TinyStories&quot;</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>/Users/alan/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.
  warnings.warn("Repo card metadata block was not found. Setting CardData to empty.")
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="training">Training<a class="headerlink" href="#training" title="Permanent link">¤</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you initialise <a href="https://wandb.ai/site">wandb</a>, the pipeline will automatically log all metrics to
wandb. However, we should pass in a dictionary with all of our hyperaparameters so they're on 
wandb. </p>
<p>We strongly encourage users to make use of wandb in order to understand the training process.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;.cache/&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;sparse-autoencoder&quot;</span><span class="p">,</span>
    <span class="nb">dir</span><span class="o">=</span><span class="s2">&quot;.cache&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_html rendered_html output_subarea">
Tracking run with wandb version 0.16.0
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
Run data is saved locally in <code>.cache/wandb/run-20231121_190511-5pvpkttg</code>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
Syncing run <strong><a href="https://wandb.ai/alan-cooney/sparse-autoencoder/runs/5pvpkttg" target="_blank">pious-yogurt-57</a></strong> to <a href="https://wandb.ai/alan-cooney/sparse-autoencoder" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
 View project at <a href="https://wandb.ai/alan-cooney/sparse-autoencoder" target="_blank">https://wandb.ai/alan-cooney/sparse-autoencoder</a>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
 View run at <a href="https://wandb.ai/alan-cooney/sparse-autoencoder/runs/5pvpkttg" target="_blank">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/5pvpkttg</a>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea output_execute_result">
<button onclick="this.nextSibling.style.display='block';this.style.display='none';">Display W&amp;B run</button><iframe src="https://wandb.ai/alan-cooney/sparse-autoencoder/runs/5pvpkttg?jupyter=true" style="border:none;width:100%;height:420px;display:none;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">cache_name</span><span class="o">=</span><span class="n">src_model_activation_hook_point</span><span class="p">,</span>
    <span class="n">layer</span><span class="o">=</span><span class="n">src_model_activation_layer</span><span class="p">,</span>
    <span class="n">source_model</span><span class="o">=</span><span class="n">src_model</span><span class="p">,</span>
    <span class="n">autoencoder</span><span class="o">=</span><span class="n">autoencoder</span><span class="p">,</span>
    <span class="n">source_dataset</span><span class="o">=</span><span class="n">source_data</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
    <span class="n">activation_resampler</span><span class="o">=</span><span class="n">activation_resampler</span><span class="p">,</span>
    <span class="n">source_data_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">run_pipeline</span><span class="p">(</span>
    <span class="n">train_batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">]),</span>
    <span class="n">max_store_size</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">,</span>
    <span class="c1"># Sizes for demo purposes (you probably want to scale these by 10x)</span>
    <span class="n">max_activations</span><span class="o">=</span><span class="mi">10_000_000</span><span class="p">,</span>
    <span class="n">resample_frequency</span><span class="o">=</span><span class="mi">2_500_000</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea">
<pre>
<code>Activations trained on:   0%|          | 0/10000000 [00:00&lt;?, ?it/s]</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RemoteDisconnected</span>                        Traceback (most recent call last)
File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:790</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool.urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    789</span> # Make the request on the HTTPConnection object
<span class="ansi-green-fg">--&gt; 790</span> response = self._make_request(
<span class="ansi-green-intense-fg ansi-bold">    791</span>     conn,
<span class="ansi-green-intense-fg ansi-bold">    792</span>     method,
<span class="ansi-green-intense-fg ansi-bold">    793</span>     url,
<span class="ansi-green-intense-fg ansi-bold">    794</span>     timeout=timeout_obj,
<span class="ansi-green-intense-fg ansi-bold">    795</span>     body=body,
<span class="ansi-green-intense-fg ansi-bold">    796</span>     headers=headers,
<span class="ansi-green-intense-fg ansi-bold">    797</span>     chunked=chunked,
<span class="ansi-green-intense-fg ansi-bold">    798</span>     retries=retries,
<span class="ansi-green-intense-fg ansi-bold">    799</span>     response_conn=response_conn,
<span class="ansi-green-intense-fg ansi-bold">    800</span>     preload_content=preload_content,
<span class="ansi-green-intense-fg ansi-bold">    801</span>     decode_content=decode_content,
<span class="ansi-green-intense-fg ansi-bold">    802</span>     **response_kw,
<span class="ansi-green-intense-fg ansi-bold">    803</span> )
<span class="ansi-green-intense-fg ansi-bold">    805</span> # Everything went great!

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:536</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool._make_request</span><span class="ansi-blue-fg">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="ansi-green-intense-fg ansi-bold">    535</span> try:
<span class="ansi-green-fg">--&gt; 536</span>     response = conn.getresponse()
<span class="ansi-green-intense-fg ansi-bold">    537</span> except (BaseSSLError, OSError) as e:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connection.py:461</span>, in <span class="ansi-cyan-fg">HTTPConnection.getresponse</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    460</span> # Get the response from http.client.HTTPConnection
<span class="ansi-green-fg">--&gt; 461</span> httplib_response = super().getresponse()
<span class="ansi-green-intense-fg ansi-bold">    463</span> try:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1378</span>, in <span class="ansi-cyan-fg">HTTPConnection.getresponse</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1377</span> try:
<span class="ansi-green-fg">-&gt; 1378</span>     response.begin()
<span class="ansi-green-intense-fg ansi-bold">   1379</span> except ConnectionError:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318</span>, in <span class="ansi-cyan-fg">HTTPResponse.begin</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    317</span> while True:
<span class="ansi-green-fg">--&gt; 318</span>     version, status, reason = self._read_status()
<span class="ansi-green-intense-fg ansi-bold">    319</span>     if status != CONTINUE:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:287</span>, in <span class="ansi-cyan-fg">HTTPResponse._read_status</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    284</span> if not line:
<span class="ansi-green-intense-fg ansi-bold">    285</span>     # Presumably, the server closed the connection before
<span class="ansi-green-intense-fg ansi-bold">    286</span>     # sending a valid response.
<span class="ansi-green-fg">--&gt; 287</span>     raise RemoteDisconnected("Remote end closed connection without"
<span class="ansi-green-intense-fg ansi-bold">    288</span>                              " response")
<span class="ansi-green-intense-fg ansi-bold">    289</span> try:

<span class="ansi-red-fg">RemoteDisconnected</span>: Remote end closed connection without response

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">ProtocolError</span>                             Traceback (most recent call last)
File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/requests/adapters.py:486</span>, in <span class="ansi-cyan-fg">HTTPAdapter.send</span><span class="ansi-blue-fg">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="ansi-green-intense-fg ansi-bold">    485</span> try:
<span class="ansi-green-fg">--&gt; 486</span>     resp = conn.urlopen(
<span class="ansi-green-intense-fg ansi-bold">    487</span>         method=request.method,
<span class="ansi-green-intense-fg ansi-bold">    488</span>         url=url,
<span class="ansi-green-intense-fg ansi-bold">    489</span>         body=request.body,
<span class="ansi-green-intense-fg ansi-bold">    490</span>         headers=request.headers,
<span class="ansi-green-intense-fg ansi-bold">    491</span>         redirect=False,
<span class="ansi-green-intense-fg ansi-bold">    492</span>         assert_same_host=False,
<span class="ansi-green-intense-fg ansi-bold">    493</span>         preload_content=False,
<span class="ansi-green-intense-fg ansi-bold">    494</span>         decode_content=False,
<span class="ansi-green-intense-fg ansi-bold">    495</span>         retries=self.max_retries,
<span class="ansi-green-intense-fg ansi-bold">    496</span>         timeout=timeout,
<span class="ansi-green-intense-fg ansi-bold">    497</span>         chunked=chunked,
<span class="ansi-green-intense-fg ansi-bold">    498</span>     )
<span class="ansi-green-intense-fg ansi-bold">    500</span> except (ProtocolError, OSError) as err:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:844</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool.urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    842</span>     new_e = ProtocolError("Connection aborted.", new_e)
<span class="ansi-green-fg">--&gt; 844</span> retries = retries.increment(
<span class="ansi-green-intense-fg ansi-bold">    845</span>     method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
<span class="ansi-green-intense-fg ansi-bold">    846</span> )
<span class="ansi-green-intense-fg ansi-bold">    847</span> retries.sleep()

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/util/retry.py:470</span>, in <span class="ansi-cyan-fg">Retry.increment</span><span class="ansi-blue-fg">(self, method, url, response, error, _pool, _stacktrace)</span>
<span class="ansi-green-intense-fg ansi-bold">    469</span> if read is False or method is None or not self._is_method_retryable(method):
<span class="ansi-green-fg">--&gt; 470</span>     raise reraise(type(error), error, _stacktrace)
<span class="ansi-green-intense-fg ansi-bold">    471</span> elif read is not None:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/util/util.py:38</span>, in <span class="ansi-cyan-fg">reraise</span><span class="ansi-blue-fg">(tp, value, tb)</span>
<span class="ansi-green-intense-fg ansi-bold">     37</span> if value.__traceback__ is not tb:
<span class="ansi-green-fg">---&gt; 38</span>     raise value.with_traceback(tb)
<span class="ansi-green-intense-fg ansi-bold">     39</span> raise value

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:790</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool.urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    789</span> # Make the request on the HTTPConnection object
<span class="ansi-green-fg">--&gt; 790</span> response = self._make_request(
<span class="ansi-green-intense-fg ansi-bold">    791</span>     conn,
<span class="ansi-green-intense-fg ansi-bold">    792</span>     method,
<span class="ansi-green-intense-fg ansi-bold">    793</span>     url,
<span class="ansi-green-intense-fg ansi-bold">    794</span>     timeout=timeout_obj,
<span class="ansi-green-intense-fg ansi-bold">    795</span>     body=body,
<span class="ansi-green-intense-fg ansi-bold">    796</span>     headers=headers,
<span class="ansi-green-intense-fg ansi-bold">    797</span>     chunked=chunked,
<span class="ansi-green-intense-fg ansi-bold">    798</span>     retries=retries,
<span class="ansi-green-intense-fg ansi-bold">    799</span>     response_conn=response_conn,
<span class="ansi-green-intense-fg ansi-bold">    800</span>     preload_content=preload_content,
<span class="ansi-green-intense-fg ansi-bold">    801</span>     decode_content=decode_content,
<span class="ansi-green-intense-fg ansi-bold">    802</span>     **response_kw,
<span class="ansi-green-intense-fg ansi-bold">    803</span> )
<span class="ansi-green-intense-fg ansi-bold">    805</span> # Everything went great!

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:536</span>, in <span class="ansi-cyan-fg">HTTPConnectionPool._make_request</span><span class="ansi-blue-fg">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="ansi-green-intense-fg ansi-bold">    535</span> try:
<span class="ansi-green-fg">--&gt; 536</span>     response = conn.getresponse()
<span class="ansi-green-intense-fg ansi-bold">    537</span> except (BaseSSLError, OSError) as e:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/urllib3/connection.py:461</span>, in <span class="ansi-cyan-fg">HTTPConnection.getresponse</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    460</span> # Get the response from http.client.HTTPConnection
<span class="ansi-green-fg">--&gt; 461</span> httplib_response = super().getresponse()
<span class="ansi-green-intense-fg ansi-bold">    463</span> try:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1378</span>, in <span class="ansi-cyan-fg">HTTPConnection.getresponse</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1377</span> try:
<span class="ansi-green-fg">-&gt; 1378</span>     response.begin()
<span class="ansi-green-intense-fg ansi-bold">   1379</span> except ConnectionError:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318</span>, in <span class="ansi-cyan-fg">HTTPResponse.begin</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    317</span> while True:
<span class="ansi-green-fg">--&gt; 318</span>     version, status, reason = self._read_status()
<span class="ansi-green-intense-fg ansi-bold">    319</span>     if status != CONTINUE:

File <span class="ansi-green-fg">/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:287</span>, in <span class="ansi-cyan-fg">HTTPResponse._read_status</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    284</span> if not line:
<span class="ansi-green-intense-fg ansi-bold">    285</span>     # Presumably, the server closed the connection before
<span class="ansi-green-intense-fg ansi-bold">    286</span>     # sending a valid response.
<span class="ansi-green-fg">--&gt; 287</span>     raise RemoteDisconnected("Remote end closed connection without"
<span class="ansi-green-intense-fg ansi-bold">    288</span>                              " response")
<span class="ansi-green-intense-fg ansi-bold">    289</span> try:

<span class="ansi-red-fg">ProtocolError</span>: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">ConnectionError</span>                           Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb Cell 26</span> line <span class="ansi-cyan-fg">1
</span><span class="ansi-green-intense-fg ansi-bold">      &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt;</span> pipeline = Pipeline(
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt;</span>     cache_name=src_model_activation_hook_point,
<span class="ansi-green-intense-fg ansi-bold">      &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt;</span>     layer=src_model_activation_layer,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=9'&gt;10&lt;/a&gt;</span>     source_data_batch_size=8,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=10'&gt;11&lt;/a&gt;</span> )
<span class="ansi-green-fg">---&gt; &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=12'&gt;13&lt;/a&gt;</span> pipeline.run_pipeline(
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=13'&gt;14&lt;/a&gt;</span>     train_batch_size=int(hyperparameters["train_batch_size"]),
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=14'&gt;15&lt;/a&gt;</span>     max_store_size=1_000_000,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=15'&gt;16&lt;/a&gt;</span>     # Sizes for demo purposes (you probably want to scale these by 10x)
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=16'&gt;17&lt;/a&gt;</span>     max_activations=10_000_000,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=17'&gt;18&lt;/a&gt;</span>     resample_frequency=2_500_000,
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#Y104sZmlsZQ%3D%3D?line=18'&gt;19&lt;/a&gt;</span> )

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/abstract_pipeline.py:186</span>, in <span class="ansi-cyan-fg">AbstractPipeline.run_pipeline</span><span class="ansi-blue-fg">(self, train_batch_size, max_store_size, max_activations, resample_frequency, validate_frequency, checkpoint_frequency)</span>
<span class="ansi-green-intense-fg ansi-bold">    183</span> for _ in range(0, max_activations, store_size):
<span class="ansi-green-intense-fg ansi-bold">    184</span>     # Generate
<span class="ansi-green-intense-fg ansi-bold">    185</span>     progress_bar.set_postfix({"stage": "generate"})
<span class="ansi-green-fg">--&gt; 186</span>     activation_store: TensorActivationStore = self.generate_activations(store_size)
<span class="ansi-green-intense-fg ansi-bold">    188</span>     # Train
<span class="ansi-green-intense-fg ansi-bold">    189</span>     progress_bar.set_postfix({"stage": "train"})

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/pipeline.py:45</span>, in <span class="ansi-cyan-fg">Pipeline.generate_activations</span><span class="ansi-blue-fg">(self, store_size)</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span> # Loop through the dataloader until the store reaches the desired size
<span class="ansi-green-intense-fg ansi-bold">     44</span> with torch.no_grad():
<span class="ansi-green-fg">---&gt; 45</span>     for batch in self.source_data:
<span class="ansi-green-intense-fg ansi-bold">     46</span>         input_ids: BatchTokenizedPrompts = batch["input_ids"].to(source_model_device)
<span class="ansi-green-intense-fg ansi-bold">     47</span>         self.source_model.forward(input_ids, stop_at_layer=self.layer + 1)  # type: ignore (TLens is typed incorrectly)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/abstract_pipeline.py:262</span>, in <span class="ansi-cyan-fg">AbstractPipeline.stateful_dataloader_iterable</span><span class="ansi-blue-fg">(dataloader)</span>
<span class="ansi-green-intense-fg ansi-bold">    227</span> @staticmethod
<span class="ansi-green-intense-fg ansi-bold">    228</span> def stateful_dataloader_iterable(
<span class="ansi-green-intense-fg ansi-bold">    229</span>     dataloader: DataLoader[TorchTokenizedPrompts]
<span class="ansi-green-intense-fg ansi-bold">    230</span> ) -&gt; Iterable[TorchTokenizedPrompts]:
<span class="ansi-green-intense-fg ansi-bold">    231</span>     """Create a stateful dataloader iterable.
<span class="ansi-green-intense-fg ansi-bold">    232</span> 
<span class="ansi-green-intense-fg ansi-bold">    233</span>     Create an iterable that maintains it's position in the dataloader between loops.
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    260</span>         Stateful iterable over the data in the dataloader.
<span class="ansi-green-intense-fg ansi-bold">    261</span>     """
<span class="ansi-green-fg">--&gt; 262</span>     yield from dataloader

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630</span>, in <span class="ansi-cyan-fg">_BaseDataLoaderIter.__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    627</span> if self._sampler_iter is None:
<span class="ansi-green-intense-fg ansi-bold">    628</span>     # TODO(https://github.com/pytorch/pytorch/issues/76750)
<span class="ansi-green-intense-fg ansi-bold">    629</span>     self._reset()  # type: ignore[call-arg]
<span class="ansi-green-fg">--&gt; 630</span> data = self._next_data()
<span class="ansi-green-intense-fg ansi-bold">    631</span> self._num_yielded += 1
<span class="ansi-green-intense-fg ansi-bold">    632</span> if self._dataset_kind == _DatasetKind.Iterable and \
<span class="ansi-green-intense-fg ansi-bold">    633</span>         self._IterableDataset_len_called is not None and \
<span class="ansi-green-intense-fg ansi-bold">    634</span>         self._num_yielded &gt; self._IterableDataset_len_called:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674</span>, in <span class="ansi-cyan-fg">_SingleProcessDataLoaderIter._next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    672</span> def _next_data(self):
<span class="ansi-green-intense-fg ansi-bold">    673</span>     index = self._next_index()  # may raise StopIteration
<span class="ansi-green-fg">--&gt; 674</span>     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
<span class="ansi-green-intense-fg ansi-bold">    675</span>     if self._pin_memory:
<span class="ansi-green-intense-fg ansi-bold">    676</span>         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:32</span>, in <span class="ansi-cyan-fg">_IterableDatasetFetcher.fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span> for _ in possibly_batched_index:
<span class="ansi-green-intense-fg ansi-bold">     31</span>     try:
<span class="ansi-green-fg">---&gt; 32</span>         data.append(next(self.dataset_iter))
<span class="ansi-green-intense-fg ansi-bold">     33</span>     except StopIteration:
<span class="ansi-green-intense-fg ansi-bold">     34</span>         self.ended = True

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:1379</span>, in <span class="ansi-cyan-fg">IterableDataset.__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1376</span>         yield formatter.format_row(pa_table)
<span class="ansi-green-intense-fg ansi-bold">   1377</span>     return
<span class="ansi-green-fg">-&gt; 1379</span> for key, example in ex_iterable:
<span class="ansi-green-intense-fg ansi-bold">   1380</span>     if self.features:
<span class="ansi-green-intense-fg ansi-bold">   1381</span>         # `IterableDataset` automatically fills missing columns with None.
<span class="ansi-green-intense-fg ansi-bold">   1382</span>         # This is done with `_apply_feature_types_on_example`.
<span class="ansi-green-intense-fg ansi-bold">   1383</span>         example = _apply_feature_types_on_example(
<span class="ansi-green-intense-fg ansi-bold">   1384</span>             example, self.features, token_per_repo_id=self._token_per_repo_id
<span class="ansi-green-intense-fg ansi-bold">   1385</span>         )

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:982</span>, in <span class="ansi-cyan-fg">BufferShuffledExamplesIterable.__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    980</span> # this is the shuffle buffer that we keep in memory
<span class="ansi-green-intense-fg ansi-bold">    981</span> mem_buffer = []
<span class="ansi-green-fg">--&gt; 982</span> for x in self.ex_iterable:
<span class="ansi-green-intense-fg ansi-bold">    983</span>     if len(mem_buffer) == buffer_size:  # if the buffer is full, pick and example from it
<span class="ansi-green-intense-fg ansi-bold">    984</span>         i = next(indices_iterator)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:678</span>, in <span class="ansi-cyan-fg">MappedExamplesIterable.__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    676</span>     yield from ArrowExamplesIterable(self._iter_arrow, {})
<span class="ansi-green-intense-fg ansi-bold">    677</span> else:
<span class="ansi-green-fg">--&gt; 678</span>     yield from self._iter()

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:693</span>, in <span class="ansi-cyan-fg">MappedExamplesIterable._iter</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    690</span>     format_dict = None
<span class="ansi-green-intense-fg ansi-bold">    692</span> if self.batched:
<span class="ansi-green-fg">--&gt; 693</span>     for key, example in iterator:
<span class="ansi-green-intense-fg ansi-bold">    694</span>         # If `batched`, first build the batch, if `batch_size` is None or &lt;=0, then the batch is the whole dataset
<span class="ansi-green-intense-fg ansi-bold">    695</span>         iterator_batch = (
<span class="ansi-green-intense-fg ansi-bold">    696</span>             iterator
<span class="ansi-green-intense-fg ansi-bold">    697</span>             if self.batch_size is None or self.batch_size &lt;= 0
<span class="ansi-green-intense-fg ansi-bold">    698</span>             else islice(iterator, self.batch_size - 1)
<span class="ansi-green-intense-fg ansi-bold">    699</span>         )
<span class="ansi-green-intense-fg ansi-bold">    700</span>         key_examples_list = [(key, example)] + list(iterator_batch)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:1114</span>, in <span class="ansi-cyan-fg">TypedExamplesIterable.__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1111</span> def __iter__(self):
<span class="ansi-green-intense-fg ansi-bold">   1112</span>     # Then for each example, `TypedExamplesIterable` automatically fills missing columns with None.
<span class="ansi-green-intense-fg ansi-bold">   1113</span>     # This is done with `_apply_feature_types_on_example`.
<span class="ansi-green-fg">-&gt; 1114</span>     for key, example in self.ex_iterable:
<span class="ansi-green-intense-fg ansi-bold">   1115</span>         yield key, _apply_feature_types_on_example(
<span class="ansi-green-intense-fg ansi-bold">   1116</span>             example, self.features, token_per_repo_id=self.token_per_repo_id
<span class="ansi-green-intense-fg ansi-bold">   1117</span>         )

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/iterable_dataset.py:320</span>, in <span class="ansi-cyan-fg">ShuffledDataSourcesArrowExamplesIterable.__iter__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    318</span> kwargs_with_shuffled_shards = _shuffle_gen_kwargs(rng, self.kwargs)
<span class="ansi-green-intense-fg ansi-bold">    319</span> formatter = PythonFormatter()
<span class="ansi-green-fg">--&gt; 320</span> for key, pa_table in self.generate_tables_fn(**kwargs_with_shuffled_shards):
<span class="ansi-green-intense-fg ansi-bold">    321</span>     for pa_subtable in pa_table.to_reader(max_chunksize=config.ARROW_READER_BATCH_SIZE_IN_DATASET_ITER):
<span class="ansi-green-intense-fg ansi-bold">    322</span>         formatted_batch = formatter.format_batch(pa_subtable)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/packaged_modules/parquet/parquet.py:87</span>, in <span class="ansi-cyan-fg">Parquet._generate_tables</span><span class="ansi-blue-fg">(self, files)</span>
<span class="ansi-green-intense-fg ansi-bold">     85</span> parquet_file = pq.ParquetFile(f)
<span class="ansi-green-intense-fg ansi-bold">     86</span> try:
<span class="ansi-green-fg">---&gt; 87</span>     for batch_idx, record_batch in enumerate(
<span class="ansi-green-intense-fg ansi-bold">     88</span>         parquet_file.iter_batches(batch_size=self.config.batch_size, columns=self.config.columns)
<span class="ansi-green-intense-fg ansi-bold">     89</span>     ):
<span class="ansi-green-intense-fg ansi-bold">     90</span>         pa_table = pa.Table.from_batches([record_batch])
<span class="ansi-green-intense-fg ansi-bold">     91</span>         # Uncomment for debugging (will print the Arrow table size and elements)
<span class="ansi-green-intense-fg ansi-bold">     92</span>         # logger.warning(f"pa_table: {pa_table} num rows: {pa_table.num_rows}")
<span class="ansi-green-intense-fg ansi-bold">     93</span>         # logger.warning('\n'.join(str(pa_table.slice(i, 1).to_pydict()) for i in range(pa_table.num_rows)))

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/pyarrow/_parquet.pyx:1366</span>, in <span class="ansi-cyan-fg">iter_batches</span><span class="ansi-blue-fg">()</span>

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/pyarrow/types.pxi:88</span>, in <span class="ansi-cyan-fg">pyarrow.lib._datatype_to_pep3118</span><span class="ansi-blue-fg">()</span>

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/datasets/download/streaming_download_manager.py:333</span>, in <span class="ansi-cyan-fg">_add_retries_to_file_obj_read_method.&lt;locals&gt;.read_with_retries</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    331</span> for retry in range(1, max_retries + 1):
<span class="ansi-green-intense-fg ansi-bold">    332</span>     try:
<span class="ansi-green-fg">--&gt; 333</span>         out = read(*args, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">    334</span>         break
<span class="ansi-green-intense-fg ansi-bold">    335</span>     except (ClientError, TimeoutError) as err:

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/fsspec/spec.py:1856</span>, in <span class="ansi-cyan-fg">AbstractBufferedFile.read</span><span class="ansi-blue-fg">(self, length)</span>
<span class="ansi-green-intense-fg ansi-bold">   1853</span> if length == 0:
<span class="ansi-green-intense-fg ansi-bold">   1854</span>     # don't even bother calling fetch
<span class="ansi-green-intense-fg ansi-bold">   1855</span>     return b""
<span class="ansi-green-fg">-&gt; 1856</span> out = self.cache._fetch(self.loc, self.loc + length)
<span class="ansi-green-intense-fg ansi-bold">   1857</span> self.loc += len(out)
<span class="ansi-green-intense-fg ansi-bold">   1858</span> return out

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/fsspec/caching.py:189</span>, in <span class="ansi-cyan-fg">ReadAheadCache._fetch</span><span class="ansi-blue-fg">(self, start, end)</span>
<span class="ansi-green-intense-fg ansi-bold">    187</span>     part = b""
<span class="ansi-green-intense-fg ansi-bold">    188</span> end = min(self.size, end + self.blocksize)
<span class="ansi-green-fg">--&gt; 189</span> self.cache = self.fetcher(start, end)  # new block replaces old
<span class="ansi-green-intense-fg ansi-bold">    190</span> self.start = start
<span class="ansi-green-intense-fg ansi-bold">    191</span> self.end = self.start + len(self.cache)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:444</span>, in <span class="ansi-cyan-fg">HfFileSystemFile._fetch_range</span><span class="ansi-blue-fg">(self, start, end)</span>
<span class="ansi-green-intense-fg ansi-bold">    433</span> headers = {
<span class="ansi-green-intense-fg ansi-bold">    434</span>     "range": f"bytes={start}-{end - 1}",
<span class="ansi-green-intense-fg ansi-bold">    435</span>     **self.fs._api._build_hf_headers(),
<span class="ansi-green-intense-fg ansi-bold">    436</span> }
<span class="ansi-green-intense-fg ansi-bold">    437</span> url = hf_hub_url(
<span class="ansi-green-intense-fg ansi-bold">    438</span>     repo_id=self.resolved_path.repo_id,
<span class="ansi-green-intense-fg ansi-bold">    439</span>     revision=self.resolved_path.revision,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    442</span>     endpoint=self.fs.endpoint,
<span class="ansi-green-intense-fg ansi-bold">    443</span> )
<span class="ansi-green-fg">--&gt; 444</span> r = http_backoff("GET", url, headers=headers)
<span class="ansi-green-intense-fg ansi-bold">    445</span> hf_raise_for_status(r)
<span class="ansi-green-intense-fg ansi-bold">    446</span> return r.content

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:267</span>, in <span class="ansi-cyan-fg">http_backoff</span><span class="ansi-blue-fg">(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    264</span>     kwargs["data"].seek(io_obj_initial_pos)
<span class="ansi-green-intense-fg ansi-bold">    266</span> # Perform request and return if status_code is not in the retry list.
<span class="ansi-green-fg">--&gt; 267</span> response = session.request(method=method, url=url, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">    268</span> if response.status_code not in retry_on_status_codes:
<span class="ansi-green-intense-fg ansi-bold">    269</span>     return response

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/requests/sessions.py:589</span>, in <span class="ansi-cyan-fg">Session.request</span><span class="ansi-blue-fg">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="ansi-green-intense-fg ansi-bold">    584</span> send_kwargs = {
<span class="ansi-green-intense-fg ansi-bold">    585</span>     "timeout": timeout,
<span class="ansi-green-intense-fg ansi-bold">    586</span>     "allow_redirects": allow_redirects,
<span class="ansi-green-intense-fg ansi-bold">    587</span> }
<span class="ansi-green-intense-fg ansi-bold">    588</span> send_kwargs.update(settings)
<span class="ansi-green-fg">--&gt; 589</span> resp = self.send(prep, **send_kwargs)
<span class="ansi-green-intense-fg ansi-bold">    591</span> return resp

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/requests/sessions.py:703</span>, in <span class="ansi-cyan-fg">Session.send</span><span class="ansi-blue-fg">(self, request, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    700</span> start = preferred_clock()
<span class="ansi-green-intense-fg ansi-bold">    702</span> # Send the request
<span class="ansi-green-fg">--&gt; 703</span> r = adapter.send(request, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">    705</span> # Total elapsed time of the request (approximately)
<span class="ansi-green-intense-fg ansi-bold">    706</span> elapsed = preferred_clock() - start

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:63</span>, in <span class="ansi-cyan-fg">UniqueRequestIdAdapter.send</span><span class="ansi-blue-fg">(self, request, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     61</span> """Catch any RequestException to append request id to the error message for debugging."""
<span class="ansi-green-intense-fg ansi-bold">     62</span> try:
<span class="ansi-green-fg">---&gt; 63</span>     return super().send(request, *args, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">     64</span> except requests.RequestException as e:
<span class="ansi-green-intense-fg ansi-bold">     65</span>     request_id = request.headers.get(X_AMZN_TRACE_ID)

File <span class="ansi-green-fg">~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/requests/adapters.py:501</span>, in <span class="ansi-cyan-fg">HTTPAdapter.send</span><span class="ansi-blue-fg">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="ansi-green-intense-fg ansi-bold">    486</span>     resp = conn.urlopen(
<span class="ansi-green-intense-fg ansi-bold">    487</span>         method=request.method,
<span class="ansi-green-intense-fg ansi-bold">    488</span>         url=url,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    497</span>         chunked=chunked,
<span class="ansi-green-intense-fg ansi-bold">    498</span>     )
<span class="ansi-green-intense-fg ansi-bold">    500</span> except (ProtocolError, OSError) as err:
<span class="ansi-green-fg">--&gt; 501</span>     raise ConnectionError(err, request=request)
<span class="ansi-green-intense-fg ansi-bold">    503</span> except MaxRetryError as e:
<span class="ansi-green-intense-fg ansi-bold">    504</span>     if isinstance(e.reason, ConnectTimeoutError):
<span class="ansi-green-intense-fg ansi-bold">    505</span>         # TODO: Remove this in 3.0.0: see #2811

<span class="ansi-red-fg">ConnectionError</span>: (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: a88fef33-195d-468c-b527-20ad75eccf2d)')</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea">
<pre>
<code>VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>LearnedActivationsL1Loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>LossReducer</td><td>█▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>MSEReconstructionLoss</td><td>█▅▅▅▄▃▃▃▂▂▂▂▂▂▁▂▁▁▁▂▁▁▂▂▂▁▁▁▁▁▁▁▂▂▂▂▁▂▁▂</td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>LearnedActivationsL1Loss</td><td>0.00027</td></tr><tr><td>LossReducer</td><td>0.01715</td></tr><tr><td>MSEReconstructionLoss</td><td>0.01688</td></tr></table><br/></div>
</div>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
 View run <strong style="color:#cdcd00">effortless-donkey-54</strong> at: <a href="https://wandb.ai/alan-cooney/sparse-autoencoder/runs/1teoia5b" target="_blank">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/1teoia5b</a><br/>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea">
Find logs at: <code>.cache/wandb/run-20231120_211221-1teoia5b/logs</code>
</div>
</div>
</div>
<p></div>
</div></p>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="training-advice">Training Advice<a class="headerlink" href="#training-advice" title="Permanent link">¤</a></h2>
<p>-- Unfinished --</p>
<ul>
<li>Check recovery loss is low while sparsity is low as well (&lt;20 L1) usually.</li>
<li>Can't be sure features are useful until you dig into them more. </li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="analysis">Analysis<a class="headerlink" href="#analysis" title="Permanent link">¤</a></h1>
<p>-- Unfinished --</p>
</div>
</div>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
        <script src="../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>